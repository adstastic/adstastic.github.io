---
title: "So how well is Claude playing Pokémon?"
date: 2025-03-22
ref: https://www.lesswrong.com/posts/HyD3khBjnBhvsp8Gb/so-how-well-is-claude-playing-pokemon
---
Quoting [Julian Bradshaw](https://www.lesswrong.com/posts/HyD3khBjnBhvsp8Gb/so-how-well-is-claude-playing-pokemon):

> The funny thing is that pokemon is a simple, railroady enough game that RNG can beat the game given enough time (and this has been done)[[6]](https://www.lesswrong.com/posts/HyD3khBjnBhvsp8Gb/so-how-well-is-claude-playing-pokemon#fnn7pl47fim8), but it turns out to take a surprising amount of cognitive architecture to play the game in a fully-sensible-looking way  
  
and insufficient smarts can be surprisingly double-edged—an RNG run would arguably be better at both leveling and navigating mazes through sheer random walkitude and willingness to bash face into every fight  
  
as opposed to getting stuck in loops or refusing to engage for bad reasons  
  
Thanks for coming to my ted talk but my overall thesis is still Executive Function is an unsolved problem  
  
(Executive Function is, reminder, goals, prioritization, attention, etc.)

> This current Claudeplayspokemon run is actually an interesting encapsulation of current limitations in llms  
  
That are more fundamental than just "LLMs don't understand spatial reasoning" (but they don't)  
  
They added a whole new memory system after Run #2 with short term and long-term text files and the ability to edit and store and archive and now he has a pretty good memory system that does improve navigation  
  
but now the lack of executive planning and goal-planning and grasp of reality is really rearing its head  
  
no amount of good memory system will save you if you just randomly see something and go:  
  
> "Oh I've achieved my goal!"  
> "Time to delete all my past files about achieving this goal!"  
  
when goal was not actually achieved[[5]](https://www.lesswrong.com/posts/HyD3khBjnBhvsp8Gb/so-how-well-is-claude-playing-pokemon#fn1efat5c1td1h)  
  
It really lacks a lot of human ability to plan, hold multiple goals at once, prioritize, and just keep a grasp of what's going on

> (re: goal orientation, you just have to witness its relative inability to simultaneously aim for the short-term goal while also leveling up its pokemon)  
  
(It can level its pokemon if that's the goal right now, or move forward if that its goal right now, but it can't simultaneously level up pokemon while also moving forward)  
  
(at least not to a human level of efficiency, it will half-heartedly do some combat while the team is healthy then immediately abandon any thought of leveling if the team is moderately injured)  
  
(It's also not capable of changing goals on the fly and going "Well I'm too injured to make it, let's get some levels and bail")

> Executive Function (agents, etc.) has always been the big missing puzzle piece, and even with copious amounts of test-time compute, tool use, scaffolding, external memory, the latest and greatest LLM still is not at even a child's level.

> the thing about ClaudePlaysPokémon is that it feels so close sometimes. Each "action" is reasoned carefully (if often on the basis of faulty knowledge), and of course Claude's irrepressible good humor is charming. If it could just plan a little better, or had a little outside direction, it'd clearly blow through the game no problem.

> it's fairly obvious if there was just someone human there to monitor Claude and give it some guidance maybe once every hour, it'd probably be 10x further through the game now  
  
That's meaningful insomuch as from a "taking people's jobs" point of view it may be possible to, even if the AI really sucks at goal planning, just chain 10 bad AIs to one employee and have them monitor

this still sucks ~9 jobs away from people

> "Executive Function" and the brain regions associated with it are the largest and most recently evolved in humans  
  
which makes sense  
  
but a lot of goal-orientation and grasp on reality stuff is reasonably well-developed in the average squirrel  
  
Not to a human level but better than most LLMs  
  
So it's not just a matter of "this is hard stuff that only elite humans do"  
  
No, a decent amount of this is fairly old stuff that's probably pretty deep in the brain, and the evolutionary pressure is presumably fairly strong to have developed it fast  
  
but the financial pressure on LLMs doesn't seem to have the same effect

> ClaudePlaysPokémon is proof that the last 6 months of AI innovation, while incredible, are still far from the true unhobbling necessary for an AI revolution. That doesn't mean 2-year AGI timelines are *wrong*, but it does feel to me like some new paradigm is yet required for them to be *right*. If you watch [the stream](https://www.twitch.tv/claudeplayspokemon) for a couple hours, I think you'll feel the same.