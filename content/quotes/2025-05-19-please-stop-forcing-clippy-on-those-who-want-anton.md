---
title: "Please Stop Forcing Clippy on Those Who Want Anton"
date: 2025-05-19
slug: "please-stop-forcing-clippy-on-those-who-want-anton"
tags:
  - quote
ref: https://www.latent.space/p/clippy-v-anton?r=4el8r&amp;utm_medium=ios&amp;triedRedirect=true
---

Quoting [swyx & Alessio](https://www.latent.space/p/clippy-v-anton?r=4el8r&utm_medium=ios&triedRedirect=true):

> the two schools of thought in building AI products:

•   **The Clippy School**: the chatty, supportive, personal “friend”/”companion”, where we prioritize “personality” and “personalization”, [disfluencies](https://www.latent.space/p/notebooklm) and [human affects](https://news.ycombinator.com/item?id=43754124).
    
•   **The Anton School**: the concise, efficient, auditable tool/assistant, where the only things we care about are either SOTA quality or speed/reliability of “good enough”.

> •   **the Antonites** cannot understand why there are so many people excited about [AI Consciousness](https://www.latent.space/p/sim-ai). They say [F*** you, show me the prompt](https://hamel.dev/blog/posts/prompt/). They sit on Hacker News and [complain about reliability](https://news.ycombinator.com/item?id=43535653). They often don’t believe that LLMs [demonstrate emergence](https://www.latent.space/p/yitay) or reasoning, and are aligned with [Team Big Workflows](https://www.latent.space/i/161759114/team-big-workflows).
    
•   **the Clippies** cannot understand why [people are creeped out by](https://x.com/xlr8harder/status/1912726846770119000) permanent, pervasive memory by default in ChatGPT. They want to [remove knobs and selectors](https://www.latent.space/p/notebooklm) from AI interfaces. They talk about Claude as “he” and have [the One Thread](https://x.com/karpathy/status/1902737525900525657). They burn AGI effigies and go to exclusive parties with [Team Big Model](https://www.latent.space/i/161759114/team-big-model).

> there is STILL a choice to be made between “**brutal honesty**” (*Anton*) and “**diplomatic/supportive**” (*Clippy*) that humans cannot unanimously decide on (often, not even the same human would agree on vs their own past preference).

Good RLHF can move models to the HHH frontier, and can even move out the frontier. Good Memory can remember preferences and personalize model behavior on the fly. But until ChatGPT can read our minds and moods, it will never really know which of the many selves we contain are currently in the driver’s seat.

> the toggle is itself an implicit admission that we have yet failed to reach AGI.

> *Everybody* says they want computers to augment us, not replace us, but then their actions often lead to the exact opposite result. **This is a battle as old as technology**.

> Steve Jobs’ famous marketing pitch for Apple - that **computers are [the bicycle of the mind](https://stratechery.com/2018/techs-two-philosophies/#v-lydOPhqW-1)** - against Mark Zuckerberg’s view of technology - “not only does Facebook want to do things for you, it wants to do things… [that] would not be done otherwise”. Less diplomatically put, **Facebook wants to fill your mind and influence it**. If Apple makes bicycles, Facebook makes opium (and connections, but that’s merely its origin story).
