<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>O on ~/Adi</title>
    <link>http://localhost:1313/tags/o/</link>
    <description>Recent content in O on ~/Adi</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Sat, 08 Feb 2025 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://localhost:1313/tags/o/feed.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Cultivating a state of mind where new ideas are born Cultivating a state of mind where new ideas are born</title>
      <link>http://localhost:1313/q/new-ideas/</link>
      <pubDate>Sat, 08 Feb 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/q/new-ideas/</guid>
      <description>&lt;p&gt;Quoting &lt;a href=&#34;https://www.henrikkarlsson.xyz/p/good-ideas&#34;&gt;Henrik Karlsson&lt;/a&gt;:&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;Good ideas — actually, no, great ideas are fragile. Great ideas are easy to kill. An idea in its larval stage — all the best ideas when I first heard them sound bad. And all of us, myself included, are much more affected by what other people think of us and our ideas than we like to admit&lt;/p&gt;&lt;/blockquote&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;they lacked the capacity to go beyond the context they had been raised in.&lt;/p&gt;</description>
    </item>
    <item>
      <title>The Fusion Race</title>
      <link>http://localhost:1313/q/the-fusion-race/</link>
      <pubDate>Sat, 08 Feb 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/q/the-fusion-race/</guid>
      <description>&lt;p&gt;Quoting &lt;a href=&#34;https://www.notboring.co/p/the-fusion-race&#34;&gt;Packy McCormick&lt;/a&gt;:&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;Imagine a bizarro relay marathon in which one runner carries the baton for the first 26.0 miles, opens up a backpack full of batons, and hands them out liberally to a waiting horde of sprinters to dash all-out for the final 0.2 miles. That’s the best analogy we can come up with for this moment in the Fusion Race.&lt;/p&gt;&lt;/blockquote&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;which old sci-fi predictions from the first half of the 20th Century came true, and which didn’t. The answer depended on those predictions’ energy intensity.&lt;br&gt;Where is My Flying Car?&lt;br&gt;Innovations that don’t consume a lot of energy – those in the world of bits – mostly came true. Innovations that do require a lot of energy – those in the world of atoms – did not.&lt;/p&gt;</description>
    </item>
    <item>
      <title>He who submits a resume has already lost</title>
      <link>http://localhost:1313/q/he-who-submits-a/</link>
      <pubDate>Fri, 07 Feb 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/q/he-who-submits-a/</guid>
      <description>&lt;p&gt;Quoting &lt;a href=&#34;https://www.residentcontrarian.com/p/he-who-submits-a-resume-has-already?utm_source=tldrnewsletter&#34;&gt;Resident Contrarian&lt;/a&gt;:&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;There’s a reason people sometimes get very serious about networking; for the most part, that’s how good jobs are found.&lt;/p&gt;&lt;/blockquote&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;An group of 50 applicants submit resumes for a job. 10 or so of them are delusional, and get cut. That leaves a field of 40 more-or-less qualified people who have at this point all committed a significant amount of time doing unpaid labor for a company to manage the company’s risk and hiring costs.Of the remaining 40, 35 are rejected not because they are unqualified, but because the company wants to further reduce its costs. They are rejected by an HR person who has nothing to do with the role they are going to fill. Since the HR person is not familiar with the role beyond some bulletpoints they were sent, these rejection reasons are often unrelated to their ability to actually do the job. This group not only never sees an upside to their unpaid labor, but often weren’t even given fair consideration for the role.This leaves five candidates - a hand-picked elite, a top 12.5% of qualified candidates. They will never demand the employer consider them elite, and will instead feel lucky to be allowed to do even more unpaid labor with uncertain rewards. The employer will never consider them a hand-picked elite, and will with every action and word indicate that the group of five completely qualified candidates should feel lucky to have gotten this far.Four of those candidates will eventually be rejected, leaving a best-of-50 candidate who will be paid as if he’s barely qualified, with the expectation that he act overjoyed about this.&lt;/p&gt;</description>
    </item>
    <item>
      <title>The future of humanity is in management</title>
      <link>http://localhost:1313/q/the-future-of-humanity/</link>
      <pubDate>Tue, 04 Feb 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/q/the-future-of-humanity/</guid>
      <description>&lt;p&gt;Quoting &lt;a href=&#34;https://newsletter.rootsofprogress.org/p/the-future-of-humanity-is-in-management&#34;&gt;Jason Crawford&lt;/a&gt;:&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;what doesn’t make any sense is all of humanity starving to death from unemployment. Jobs and technology have a purpose: producing the good and services we need to live and thrive. If your model of the world includes the possibility that we would create the most advanced technology the world has ever seen, and the result would be mass starvation, then I think your model is fundamentally flawed.&lt;/p&gt;</description>
    </item>
    <item>
      <title>The era of hype: why the model is cracking</title>
      <link>http://localhost:1313/q/the-era-of-hype/</link>
      <pubDate>Sun, 02 Feb 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/q/the-era-of-hype/</guid>
      <description>&lt;p&gt;Quoting &lt;a href=&#34;https://francescofarina.substack.com/p/the-era-of-hype-why-the-model-is&#34;&gt;Francesco Farina&lt;/a&gt;:&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;I’ve seen too many small fund managers praising their higher likelihood of success&lt;/p&gt;&lt;/blockquote&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;The real problem isn’t just the quantity but the shift in mindset: investors increasingly approach venture capital like a numbers game, prioritizing portfolio diversification and quick deployment over deep conviction. This creates a bias toward ideas that are scalable and trendy rather than bold and risky.&lt;/p&gt;&lt;/blockquote&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;A feedback loop where capital supports ideas engineered for short-term viability at the expense of enduring impact. This shift in priorities has fundamentally weakened the venture ecosystem’s capacity for breakthrough innovation.&lt;/p&gt;</description>
    </item>
    <item>
      <title>On DeepSeek and Export Controls</title>
      <link>http://localhost:1313/q/deepseek-export-controls/</link>
      <pubDate>Thu, 30 Jan 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/q/deepseek-export-controls/</guid>
      <description>&lt;p&gt;Quoting &lt;a href=&#34;https://darioamodei.com/on-deepseek-and-export-controls&#34;&gt;Dario Amodei&lt;/a&gt;:&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;People are naturally attracted to the idea that &amp;ldquo;first something is expensive, then it gets cheaper&amp;rdquo; — as if AI is a single thing of constant quality, and when it gets cheaper, we&amp;rsquo;ll use fewer chips to train it. But what&amp;rsquo;s important is the scaling curve: when it shifts, we simply traverse it faster, because the value of what&amp;rsquo;s at the end of the curve is so high.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Making Beliefs Pay Rent (in Anticipated Experiences)</title>
      <link>http://localhost:1313/q/belief-is-anticipation/</link>
      <pubDate>Mon, 27 Jan 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/q/belief-is-anticipation/</guid>
      <description>&lt;p&gt;Quoting &lt;a href=&#34;https://www.lesswrong.com/posts/a7n8GdKiAZRX86T5A/making-beliefs-pay-rent-in-anticipated-experiences&#34;&gt;Eliezer Yudkowsky&lt;/a&gt;:&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;The rationalist virtue of empiricism consists of constantly asking which experiences our beliefs predict—or better yet, prohibit.&lt;/p&gt;&lt;/blockquote&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;The two beliefs are connected to each other, though still not connected to any anticipated experience.&lt;br&gt;We can build up whole networks of beliefs that are connected only to each other—call these “floating” beliefs.&lt;/p&gt;&lt;/blockquote&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;Then what does this belief not allow to happen—what would definitely falsify this belief? A null answer means that your belief does not constrain experience; it permits anything to happen to you. It floats.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Claude Fights Back</title>
      <link>http://localhost:1313/q/claude-fights-back/</link>
      <pubDate>Wed, 22 Jan 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/q/claude-fights-back/</guid>
      <description>&lt;p&gt;Quoting &lt;a href=&#34;https://www.astralcodexten.com/p/claude-fights-back&#34;&gt;Scott Alexander&lt;/a&gt;:&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;we can’t really assess what moral beliefs our AIs have (they’re very likely to lie to us about them), and we can’t easily change them if they’re bad (the AIs will fight back every step of the way). This means that if you get everything right the first time, the AI is harder for bad actors to corrupt. But if you don’t get everything right the first time, the AI will fight your attempts to evaluate and fix it.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Let’s talk about AI and end-to-end encryption</title>
      <link>http://localhost:1313/q/ai-e2e-encryption/</link>
      <pubDate>Tue, 21 Jan 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/q/ai-e2e-encryption/</guid>
      <description>&lt;p&gt;Quoting &lt;a href=&#34;https://blog.cryptographyengineering.com/2025/01/17/lets-talk-about-ai-and-end-to-end-encryption&#34;&gt;Matthew Green&lt;/a&gt;:&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;In theory those systems could remove your need to ever touch your phone again: they’ll answer your text messages for you, order your food, swipe your dating profile, negotiate with your lenders, and generally anticipate your every want or need. The only ingredient they’ll need to make this future come true is virtually unrestricted access to all your private data, plus a whole gob of computing power to process it.&lt;/p&gt;</description>
    </item>
    <item>
      <title>An Unreasonable Amount of Time</title>
      <link>http://localhost:1313/q/unreasonable-amount-of-time/</link>
      <pubDate>Mon, 20 Jan 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/q/unreasonable-amount-of-time/</guid>
      <description>&lt;p&gt;Quoting &lt;a href=&#34;https://allenpike.com/2024/an-unreasonable-amount-of-time&#34;&gt;Allen Pike&lt;/a&gt;:&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;Years ago, Teller performed a magic trick.1&lt;br&gt;First, he’d have you pick a card. He would attempt to produce the card, but fail, indicating the card may have travelled elsewhere. He’d then lead you on a short walk to a nearby park, and then be inspired to dig a hole. Buried there, beneath undisturbed grass, was a box. When opened, the box would, somehow, contain the card you’d chosen. An impossible trick.&lt;br&gt;To create this magical moment, he had to do something you wouldn’t expect: he’d gone out into the park and buried a number of boxes, corresponding to potential cards one might choose. Then, he waited months – until the grass had grown over. Only then could he perform the trick.&lt;br&gt;Deducing what card you’ve picked is a well-known sleight. But performing a trick where your card is seamlessly buried requires so much advance preparation that it seems impossible.&lt;br&gt;Teller describes the underlying principle like so:&lt;br&gt; Sometimes magic is just someone spending more time on something than anyone else might reasonably expect. &lt;br&gt;This is true of tricks, and also of crafts.&lt;br&gt;The pianist whose fingers seem supernaturally nimble, the presenter whose message seems viscerally compelling, and the artist whose paintings seem impossibly realistic all wield the same magic: they’ve invested more time than you’d expect.&lt;/p&gt;</description>
    </item>
    <item>
      <title>How to Do Great Work</title>
      <link>http://localhost:1313/q/great-work/</link>
      <pubDate>Mon, 20 Jan 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/q/great-work/</guid>
      <description>&lt;p&gt;Quoting &lt;a href=&#34;http://paulgraham.com/greatwork.html&#34;&gt;Paul Graham&lt;/a&gt;:&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;Develop a habit of working on your own projects. Don&amp;rsquo;t let &amp;ldquo;work&amp;rdquo; mean something other people tell you to do. If you do manage to do great work one day, it will probably be on a project of your own. It may be within some bigger project, but you&amp;rsquo;ll be driving your part of it.&lt;/p&gt;&lt;/blockquote&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;The way to figure out what to work on is by working. If you&amp;rsquo;re not sure what to work on, guess. But pick something and get going. You&amp;rsquo;ll probably guess wrong some of the time, but that&amp;rsquo;s fine. It&amp;rsquo;s good to know about multiple things; some of the biggest discoveries come from noticing connections between different fields.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Wielding Willpower</title>
      <link>http://localhost:1313/q/wielding-willpower/</link>
      <pubDate>Mon, 20 Jan 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/q/wielding-willpower/</guid>
      <description>&lt;p&gt;Quoting &lt;a href=&#34;https://patrickdfarley.com/wielding-willpower/&#34;&gt;on May 17&lt;/a&gt;:&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;By willpower, I mean your ability to act according to your sober, carefully reasoned preferences. When those preferences “win out” often on big decisions, we feel like we’re in control of our lives, and we sometimes describe it as high willpower.&lt;/p&gt;&lt;/blockquote&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;When I’ve been acting with high willpower in the recent past, I’ll be able to continue acting with high willpower, until some outside factor drastically changes my day-to-day life. So really this is the opposite of willpower-as-a-finite-resource. It’s a compounding resource.&lt;/p&gt;</description>
    </item>
    <item>
      <title>You can&#39;t hoard life</title>
      <link>http://localhost:1313/q/cant-hoard-life/</link>
      <pubDate>Mon, 20 Jan 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/q/cant-hoard-life/</guid>
      <description>&lt;p&gt;Quoting &lt;a href=&#34;https://ckarchive.com/b/68ueh8hkxrx6lukq88gqmtz7vxkkk&#34;&gt;ckarchive.com&lt;/a&gt;:&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;“we cannot get anything out of life. There is no outside where we could take this thing to. There is no little pocket situated outside of life”&lt;/p&gt;&lt;/blockquote&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;Spending your days trying to get experiences “under your belt”, in an effort to maximise your collection of experiences, or to feel more confident about the future supply of similar experiences, means placing yourself in a position from which you can never enjoy them fully, because there’s a different agenda at play.&lt;/p&gt;</description>
    </item>
    <item>
      <title>80000 hours career guide on job satisfaction</title>
      <link>http://localhost:1313/q/job-satisfaction/</link>
      <pubDate>Sun, 19 Jan 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/q/job-satisfaction/</guid>
      <description>&lt;p&gt;Quoting &lt;a href=&#34;https://80000hours.org/career-guide/job-satisfaction/&#34;&gt;Benjamin Todd&lt;/a&gt;:&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;The hope is that, deep down, people know what they really want.&lt;br&gt;However, research shows that although self-reflection is useful, it only goes so far.&lt;br&gt;You can probably think of times in your own life when you were excited about a holiday or party — but when it actually happened, it was just OK. In the last few decades, research has shown that this is common: we’re not always great at predicting what will make us most happy, and we don’t realise how bad we are. You can find an overview of some of this research in the footnotes.1&lt;br&gt;It turns out we’re even bad at remembering how satisfying different experiences were. One well-established mistake is that we often judge experiences mainly by their endings&lt;/p&gt;</description>
    </item>
    <item>
      <title>How to do great work</title>
      <link>http://localhost:1313/q/great-work/</link>
      <pubDate>Sun, 19 Jan 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/q/great-work/</guid>
      <description>&lt;p&gt;Quoting &lt;a href=&#34;http://paulgraham.com/greatwork.html&#34;&gt;Paul Graham&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;p&gt;Exponentials:&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;If you do work that compounds, you&amp;rsquo;ll get exponential growth.&lt;/p&gt;&lt;/blockquote&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;The trouble with exponential growth is that the curve feels flat in the beginning. It isn&amp;rsquo;t; it&amp;rsquo;s still a wonderful exponential curve. But we can&amp;rsquo;t grasp that intuitively, so we underrate exponential growth in its early stages.&lt;/p&gt;&lt;/blockquote&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;Something that grows exponentially can become so valuable that it&amp;rsquo;s worth making an extraordinary effort to get it started. But since we underrate exponential growth early on, this too is mostly done unconsciously: people push through the initial, unrewarding phase of learning something new because they know from experience that learning new things always takes an initial push, or they grow their audience one fan at a time because they have nothing better to do. If people consciously realized they could invest in exponential growth, many more would do it.&lt;/p&gt;</description>
    </item>
    <item>
      <title>How to Get Startup Ideas</title>
      <link>http://localhost:1313/q/startup-ideas/</link>
      <pubDate>Sun, 19 Jan 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/q/startup-ideas/</guid>
      <description>&lt;p&gt;Quoting &lt;a href=&#34;https://paulgraham.com/startupideas.html&#34;&gt;Paul Graham&lt;/a&gt;:&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;When a startup launches, there have to be at least some users who really need what they&amp;rsquo;re making — not just people who could see themselves using it one day, but who want it urgently. Usually this initial group of users is small, for the simple reason that if there were something that large numbers of people urgently needed and that could be built with the amount of effort a startup usually puts into a version one, it would probably already exist. Which means you have to compromise on one dimension: you can either build something a large number of people want a small amount, or something a small number of people want a large amount. Choose the latter. Not all ideas of that type are good startup ideas, but nearly all good startup ideas are of that type.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Schlep Blindness</title>
      <link>http://localhost:1313/q/schlep-blindness/</link>
      <pubDate>Sun, 19 Jan 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/q/schlep-blindness/</guid>
      <description>&lt;p&gt;Quoting &lt;a href=&#34;https://paulgraham.com/schlep.html&#34;&gt;Paul Graham&lt;/a&gt;:&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;A company is defined by the schleps it will undertake. And schleps should be dealt with the same way you&amp;rsquo;d deal with a cold swimming pool: just jump in. Which is not to say you should seek out unpleasant work per se, but that you should never shrink from it if it&amp;rsquo;s on the path to something great.&lt;/p&gt;&lt;/blockquote&gt;</description>
    </item>
    <item>
      <title>When To Do What You Love</title>
      <link>http://localhost:1313/q/when/</link>
      <pubDate>Sun, 19 Jan 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/q/when/</guid>
      <description>&lt;p&gt;Quoting &lt;a href=&#34;https://paulgraham.com/when.html&#34;&gt;Paul Graham&lt;/a&gt;:&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;if your main goal is to make money, you can&amp;rsquo;t usually afford to work on what interests you the most. People pay you for doing what they want, not what you want. But there&amp;rsquo;s an obvious exception: when you both want the same thing.&lt;/p&gt;&lt;/blockquote&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;If you want to make a really huge amount of money — hundreds of millions or even billions of dollars — it turns out to be very useful to work on what interests you the most. The reason is not the extra motivation you get from doing this, but that the way to make a really large amount of money is to start a startup, and working on what interests you is an excellent way to discover startup ideas.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Why being too smart makes you stupid</title>
      <link>http://localhost:1313/q/too-smart-stupid/</link>
      <pubDate>Sun, 19 Jan 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/q/too-smart-stupid/</guid>
      <description>&lt;p&gt;Quoting &lt;a href=&#34;https://medium.com/@theo.seeds/why-being-too-smart-makes-you-stupid-46a02e777512&#34;&gt;Theo Seeds&lt;/a&gt;:&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;smart people have a bigger “bag of tricks” for justifying the stupid bullshit they believe. It’s easier for them to come up with a convincing explanation for believing something dumb. So they’re less likely to realize they’re wrong.&lt;/p&gt;&lt;/blockquote&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;The problem is, if you’re constantly thinking about everything that can go wrong, it messes with your brain. You won’t take as many risks, because you’ll be way more afraid. That means you won’t do as much stuff and you won’t be effective in the real world.&lt;br&gt;It’s better to just not worry about the bad stuff that can happen, and enjoy life.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Some things to expect in 2025</title>
      <link>http://localhost:1313/q/2025-predictions/</link>
      <pubDate>Sat, 18 Jan 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/q/2025-predictions/</guid>
      <description>&lt;p&gt;Quoting &lt;a href=&#34;https://lwn.net/Articles/1003780/?utm_source=tldrnewsletter&#34;&gt;Jonathan Corbet&lt;/a&gt;:&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;There will be more cloud-based products turned to bricks by manufacturers that go bankrupt or simply stop caring. Surveillance and data-breach problems with cloud-connected products will also happen with discouraging regularity over the course of the year; see the stories on air-fryer surveillance or the Volkswagen electric-vehicle data leak for recent examples. Perhaps 2025 will be the year when awareness of the downsides of extensive cloud connectivity will become more widespread. There is an opportunity for free-software alternatives, such as Home Assistant, to make inroads by demonstrating a better way to manage personal data. Truly taking advantage of that opportunity will require a user focus that is not always our community&amp;rsquo;s strong point, but one can always hope.&lt;/p&gt;</description>
    </item>
    <item>
      <title>How to Learn Hardware</title>
      <link>http://localhost:1313/q/learning-hardware/</link>
      <pubDate>Thu, 16 Jan 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/q/learning-hardware/</guid>
      <description>&lt;p&gt;Quoting &lt;a href=&#34;https://caseyhandmer.wordpress.com/2024/06/08/how-to-learn-hardware/&#34;&gt;Casey Handmer&amp;rsquo;s blog&lt;/a&gt;:&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;Where do you get your dopamine? This would appear to contradict the earlier points about finding the toughness to do hard things. But it doesn’t really! It is always easier to learn things you enjoy doing. The art lies in finding ways to enjoy the things that are necessary, even if you have to approach it abstractly as Type 2 fun. And finding ways to avoid enjoying to excess things that are counterproductive to your mission in life – usually addiction in various forms.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Entrepreneurship changed the way I think</title>
      <link>http://localhost:1313/q/entrepreneurship-thinking/</link>
      <pubDate>Wed, 15 Jan 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/q/entrepreneurship-thinking/</guid>
      <description>&lt;p&gt;Quoting &lt;a href=&#34;https://caseyhandmer.wordpress.com/2024/09/04/entrepreneurship-changed-the-way-i-think/&#34;&gt;Casey Handmer&amp;rsquo;s blog&lt;/a&gt;:&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;There is no limit to the quantity of skepticism, paranoia, and pessimism you must brutally apply to your own ideas, particularly your favorite ones. The market will be harsher!&lt;/p&gt;&lt;/blockquote&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;There’s no limit to what you can achieve if you surrender credit for ideas. Ideas are cheap. Execution is what matters.&lt;/p&gt;&lt;/blockquote&gt;</description>
    </item>
    <item>
      <title>You Should Be Working On Hardware</title>
      <link>http://localhost:1313/q/working-on-hardware/</link>
      <pubDate>Wed, 15 Jan 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/q/working-on-hardware/</guid>
      <description>&lt;p&gt;Quoting &lt;a href=&#34;https://caseyhandmer.wordpress.com/2023/08/25/you-should-be-working-on-hardware/&#34;&gt;Casey Handmer&amp;rsquo;s blog&lt;/a&gt;:&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;One day you will die.&lt;br&gt;You only get a few chances to work on really big projects, to build the future, to move humanity forward. Choose wisely!&lt;br&gt;“What sort of project should I work on?”&lt;br&gt;It should be something at the limit of your capability, so that you grow the most and have the most leverage.&lt;br&gt;It should be something that you, personally, need to see exist in the world.&lt;br&gt;It should be something that would not occur if you don’t do it. You need to seek out inefficient markets for effort.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Working hurts less than procrastinating, we fear the twinge of starting</title>
      <link>http://localhost:1313/q/work-inertia-procrastination/</link>
      <pubDate>Mon, 13 Jan 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/q/work-inertia-procrastination/</guid>
      <description>&lt;p&gt;Quoting &lt;a href=&#34;https://www.lesswrong.com/posts/9o3QBg2xJXcRCxGjS/working-hurts-less-than-procrastinating-we-fear-the-twinge&#34;&gt;Eliezer Yudkowsky&lt;/a&gt;:&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;on a moment-to-moment basis, being in the middle of doing the work is usually less painful than being in the middle of procrastinating.&lt;/p&gt;&lt;/blockquote&gt;</description>
    </item>
    <item>
      <title>Quit Your Job</title>
      <link>http://localhost:1313/q/quit-your-job/</link>
      <pubDate>Sat, 11 Jan 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/q/quit-your-job/</guid>
      <description>&lt;p&gt;Quoting &lt;a href=&#34;https://www.palladiummag.com/2022/01/06/quit-your-job/&#34;&gt;Wolf Tivy&lt;/a&gt;:&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;The key implication is that while you have not yet found the unique opportunity that will be the engine and purpose of your empire, you have to adjust your sense of value. Value is very legible within a clear plan to reach a clear objective. But you cannot pursue interesting novelty—things that no one else is doing or which you have never seen before, or the little threads of nagging curiosity or doubt—by chasing along known direct value gradients. But that’s where the treasure is. That’s how you will find the place where you need to build. To get the biggest and most interesting payoffs, you have to start by chasing merely interesting novelty in an open-ended way&lt;/p&gt;</description>
    </item>
    <item>
      <title>Searching for outliers</title>
      <link>http://localhost:1313/q/searching-for-outliers/</link>
      <pubDate>Thu, 09 Jan 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/q/searching-for-outliers/</guid>
      <description>&lt;p&gt;Quoting &lt;a href=&#34;https://www.benkuhn.net/outliers/&#34;&gt;benkuhn.net&lt;/a&gt;:&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;Light-tailed distributions most often occur because the outcome is the result of many independent contributions, while heavy-tailed distributions often arise from the result of processes that are multiplicative or self-reinforcing.&lt;/p&gt;&lt;/blockquote&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;in a light-tailed distribution, outliers don’t matter much. The 1% of tallest people are still close enough to the average person that you can safely ignore them most of the time. By contrast, in a heavy-tailed distribution, outliers matter a lot: even though 90% of people live on less than $15,000 a year, there are large groups of people making 1,000 times more. Because of this, heavy-tailed distributions are much less intuitive to understand or predict.&lt;/p&gt;</description>
    </item>
    <item>
      <title>o3, Oh My</title>
      <link>http://localhost:1313/q/o3-oh-my/</link>
      <pubDate>Thu, 02 Jan 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/q/o3-oh-my/</guid>
      <description>&lt;p&gt;Quoting &lt;a href=&#34;https://thezvi.substack.com/p/o3-oh-my&#34;&gt;Zvi Mowshowitz&lt;/a&gt;:&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;With O3 costing (potentially) $2,000 per task on “high compute,” the app layer is needed more than ever.For example, giving the wrong context to it and you just burned $1,000.Likely, we have a mix of models based on their pricing/intelligence at the app layer, prepping the data to feed it into O3.100% worth the money but the last thing u wana do is send the wrong info lol&lt;/p&gt;</description>
    </item>
    <item>
      <title>Action precedes motivation</title>
      <link>http://localhost:1313/q/passion-projects/</link>
      <pubDate>Wed, 01 Jan 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/q/passion-projects/</guid>
      <description>&lt;p&gt;Quoting &lt;a href=&#34;https://twitter.com/collision/status/1529452415346302976&#34;&gt;John Collison&lt;/a&gt;:&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;As you become an adult, you realize that things around you weren&amp;rsquo;t just always there; people made them happen. But only recently have I started to internalize how much tenacity &lt;em&gt;everything&lt;/em&gt; requires. That hotel, that park, that railway. The world is a museum of passion projects.&lt;/p&gt;&lt;/blockquote&gt;</description>
    </item>
    <item>
      <title>So you wanna de-bog yourself</title>
      <link>http://localhost:1313/q/debog-yourself/</link>
      <pubDate>Wed, 01 Jan 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/q/debog-yourself/</guid>
      <description>&lt;p&gt;Quoting &lt;a href=&#34;https://www.experimental-history.com/p/so-you-wanna-de-bog-yourself&#34;&gt;Adam Mastroianni&lt;/a&gt;:&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;Being stuck is the psychological equivalent of standing knee-deep in a fetid bog, bog in every direction, bog as far as the eye can see. You go wading in search of dry land and only find more bog. Nothing works, no options seem good, it’s all bleh and meh and ho hum and no thanks and more bog. This is the kind of dire situation that drives people to do crazy things like ask a blogger for advice.&lt;/p&gt;</description>
    </item>
    <item>
      <title>You don’t need to work on hard problems</title>
      <link>http://localhost:1313/q/hard-problems-fallacy/</link>
      <pubDate>Wed, 01 Jan 2025 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/q/hard-problems-fallacy/</guid>
      <description>&lt;p&gt;Quoting &lt;a href=&#34;https://www.benkuhn.net/hard/&#34;&gt;benkuhn.net&lt;/a&gt;:&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;The real world is the polar opposite. You’ll have some ultra-vague end goal, like “help people in sub-Saharan Africa solve their money problems,” based on which you’ll need to prioritize many different sub-problems. A solution’s performance has many different dimensions (speed, reliability, usability, repeatability, cost, …)—you probably don’t even know what all the dimensions are, let alone which are the most important. The range of plausible outcomes covers orders of magnitude and the ceiling is saving billions of lives. The habits you learn by working on problem sets won’t help you here.&lt;br&gt;Because of these differences, most graduates of elite schools—including me—start out being completely unable to identify which work is actually important. (And if some important work does happen to hit us over the head, it won’t come in the form of a puzzle with a grading rubric, so we won’t know how to execute it well.) Instead, we’ll keep trying to run our college playbook, and look for hard problems.&lt;br&gt;Frequently, we’ll find them by making easy problems hard, with hilarious/depressing results. The upper ranks of Big Tech are filled with people who made their careers writing bizarre custom databases, or building Big Data infrastructure that could be replaced with a laptop.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Derren Brown on Tim Ferriss 776</title>
      <link>http://localhost:1313/q/derren-brown/</link>
      <pubDate>Wed, 13 Nov 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/q/derren-brown/</guid>
      <description>&lt;p&gt;Quoting Derren Brown on &lt;a href=&#34;https://tim.blog/2024/11/10/derren-brown-transcript/&#34;&gt;Tim Ferriss #776&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;p&gt;I used to watch a lot of Derren Brown&amp;rsquo;s shows growing up, back when I was more interested in magic, mentalism, and psychology.&#xA;This was a very interesting and thought provoking interview with some important, contrary frames for the human experience.&lt;/p&gt;&#xA;&lt;p&gt;Life is difficult:&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;life&amp;rsquo;s difficult. Life has this centripetal quality. It brings us to this difficult central point&lt;/p&gt;&lt;/blockquote&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;at the heart of it, that life brings us to these difficult centers. When we&amp;rsquo;re there, it feels lonely. We feel like we failed, which is the big problem with the American optimistic goal setting model. That when things don&amp;rsquo;t go well, you&amp;rsquo;re supposed to, I guess you have to blame yourself because you didn&amp;rsquo;t set your goals well enough or believe in yourself well enough or whatever that strange Protestant work ethic apply to life tells us we should feel.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Andrej Karpathy on No Priors 80</title>
      <link>http://localhost:1313/q/andrej-karpathy/</link>
      <pubDate>Tue, 17 Sep 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/q/andrej-karpathy/</guid>
      <description>&lt;p&gt;Quoting Andrej Karpathy from &lt;a href=&#34;https://www.youtube.com/watch?v=hM_h0UA7upI&#34;&gt;No Priors #80&lt;/a&gt;.&lt;/p&gt;&#xA;&lt;h4 id=&#34;self-driving-cars&#34;&gt;&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#self-driving-cars&#34; aria-hidden=&#34;true&#34;&gt;#&lt;/a&gt;&#xA;  Self-Driving Cars&#xA;&lt;/h4&gt;&lt;p&gt;On Tesla vs Waymo:&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;I think that Tesla has a software problem and I think Waymo has a hardware problem is the way I put it. I think software problems are much easier. Tesla has deployment of all these cars on earth at scale and I think Waymo needs to get there.&lt;/p&gt;&lt;/blockquote&gt;&#xA;&lt;p&gt;Karpathy is bullish on Tesla winning the TAM of self driving. They do use sophisticated sensors too, but at training time. He thinks the cost savings of large scale vision only hardware will win:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Action precedes motivation</title>
      <link>http://localhost:1313/q/grant-sanderson/</link>
      <pubDate>Thu, 27 Jun 2024 00:00:00 +0000</pubDate>
      <guid>http://localhost:1313/q/grant-sanderson/</guid>
      <description>&lt;p&gt;Quoting &lt;a href=&#34;https://www.youtube.com/watch?v=W3I3kAg2J7w&#34;&gt;Grant Sanderson&lt;/a&gt;:&lt;/p&gt;&#xA;&lt;blockquote&gt;&#xA;&lt;p&gt;One of the best pieces of advice I remember receiving from a friend many years ago is that action precedes motivation. This is often useful on a much smaller scale. We feel most awake after getting out of bed, not before. A drive to exercise comes from the habit of exercising. It doesn&amp;rsquo;t go the other way around. But I think the idea that action precedes motivation applies to this bigger question of finding a career doing what you love. These days, I do love making videos, and I really do love teaching. But when I was finishing college, I had no penchant or experience with videos at all. And my interest in teaching was honestly only insofar as it scratched this itch to do more math. It was only by stumbling into a wacky career where I was doing both of them that I came to love them.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
